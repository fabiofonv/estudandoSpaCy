{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCHER\n",
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16571425990740197027, 5, 6)]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LIKE_EMAIL\": True}]\n",
    "matcher.add(\"EMAIL_ADDRESS\", [pattern])\n",
    "doc = nlp(\"Esse é um email: fabiofonv@hotmail.com\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "print(matches) # [(LEXEME, START_TOKEN, END_TOKEN)]\n",
    "\n",
    "# for token in doc:\n",
    "#     if token.like_email:\n",
    "#         print(f\"Email encontrado: {token.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMAIL_ADDRESS\n"
     ]
    }
   ],
   "source": [
    "print(nlp.vocab[matches[0][0]].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin Luther King Jr. (nascido Michael King Jr.; Atlanta, 15 de janeiro de 1929 – Memphis, 4 de abril de 1968) foi um pastor batista e ativista político estadunidense que se tornou a figura mais proeminente e líder do movimento dos direitos civis nos Estados Unidos de 1955 até seu assassinato em 1968. King é amplamente conhecido pela aplicação do princípio da desobediência civil[1] e da não violência[1] à luta por direitos políticos, inspirado por suas crenças cristãs e pelo ativismo não violento de Mahatma Gandhi.\n",
      "\n",
      "King liderou em 1955 o boicote aos ônibus de Montgomery e posteriormente se tornou o primeiro presidente da Conferência da Liderança Cristã do Sul (abreviado em inglês como SCLC). Como presidente da SCLC, ele liderou sem sucesso em 1962 a luta contra a segregação em Albany, e foi um dos participantes que organizaram os protestos não violentos de 1963 em Birmingham. King ajudou na organização da Marcha sobre Washington onde ele ditou seu famoso discurso \"Eu Tenho um Sonho\" (em inglês: \"I Have a Dream\") aos pés do Memorial de Lincoln.\n",
      "\n",
      "Em 14 de outubro de 1964, King ganhou o Prêmio Nobel da Paz por combater o racismo nos Estados Unidos através da resistência não violenta. Em 1965, ele ajudou a organizar as Marchas de Selma a Montgomery. Nos seus últimos anos, ele ampliou seu ativismo contra a pobreza e a Guerra do Vietnã. O diretor do FBI J. Edgar Hoover achava King um radical e fez dele alvo do programa de contrainteligência a partir de 1963. Os agentes do FBI o investigaram por possíveis laços comunistas, ameaçaram tornar público suas supostas relações extraconjugais e o denunciaram para agentes governamentais e, em 1964, mandaram a King uma carta ameaçadora anônima, o qual ele interpretou como uma tentativa de alguém a incentivá-lo a cometer suicídio.\n",
      "\n",
      "Antes de sua morte, King estava planejando uma ocupação em Washington, D.C., que seria denominada Campanha dos Pobres, quando ele foi assassinado em 4 de abril de 1968, em Memphis. Sua morte causou forte reação e foi seguida por manifestações em várias cidades dos Estados Unidos. Alegações que o assassino convicto de King, James Earl Ray, ter sido coagido ou agido em conjunto com agentes do governo persistiram por décadas após o tiroteio. King foi premiado postumamente com a Medalha Presidencial da Liberdade e a Medalha de Ouro do Congresso. O Dia de Martin Luther King foi estabelecido como feriado em cidades e estados dos Estados Unidos a partir de 1971; o feriado foi promulgado a nível federal por uma legislação assinada pelo presidente Ronald Reagan em 1986. Centenas de estradas nos EUA foram renomeadas em sua honra, e um condado em Washington foi dedicado a ele. O Martin Luther King Jr. Memorial no National Mall em Washington D.C. foi inaugurado em sua homenagem em 2011. \n"
     ]
    }
   ],
   "source": [
    "with open(\"wiki_mlk.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "(451313080118390996, 0, 1) Martin\n",
      "(451313080118390996, 1, 2) Luther\n",
      "(451313080118390996, 2, 3) King\n",
      "(451313080118390996, 3, 4) Jr.\n",
      "(451313080118390996, 6, 7) Michael\n",
      "(451313080118390996, 7, 8) King\n",
      "(451313080118390996, 8, 9) Jr.\n",
      "(451313080118390996, 10, 11) Atlanta\n",
      "(451313080118390996, 17, 18) –\n",
      "(451313080118390996, 18, 19) Memphis\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern])\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "(451313080118390996, 0, 1) Martin\n",
      "(451313080118390996, 0, 2) Martin Luther\n",
      "(451313080118390996, 1, 2) Luther\n",
      "(451313080118390996, 0, 3) Martin Luther King\n",
      "(451313080118390996, 1, 3) Luther King\n",
      "(451313080118390996, 2, 3) King\n",
      "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
      "(451313080118390996, 1, 4) Luther King Jr.\n",
      "(451313080118390996, 2, 4) King Jr.\n",
      "(451313080118390996, 3, 4) Jr.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern])\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "(451313080118390996, 502, 507) Martin Luther King Jr. Memorial\n",
      "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
      "(451313080118390996, 265, 269) FBI J. Edgar Hoover\n",
      "(451313080118390996, 6, 9) Michael King Jr.\n",
      "(451313080118390996, 188, 191) \"I Have\n",
      "(451313080118390996, 400, 403) James Earl Ray\n",
      "(451313080118390996, 443, 446) Martin Luther King\n",
      "(451313080118390996, 17, 19) – Memphis\n",
      "(451313080118390996, 49, 51) Estados Unidos\n",
      "(451313080118390996, 93, 95) Mahatma Gandhi\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
      "(451313080118390996, 6, 9) Michael King Jr.\n",
      "(451313080118390996, 10, 11) Atlanta\n",
      "(451313080118390996, 17, 19) – Memphis\n",
      "(451313080118390996, 49, 51) Estados Unidos\n",
      "(451313080118390996, 59, 60) King\n",
      "(451313080118390996, 93, 95) Mahatma Gandhi\n",
      "(451313080118390996, 97, 98) King\n",
      "(451313080118390996, 106, 107) Montgomery\n",
      "(451313080118390996, 115, 116) Conferência\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key=lambda x: x[1])\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(451313080118390996, 97, 99) King liderou\n",
      "(451313080118390996, 164, 166) King ajudou\n",
      "(451313080118390996, 210, 212) King ganhou\n",
      "(451313080118390996, 265, 270) FBI J. Edgar Hoover achava\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"},\n",
    "           {\"POS\": \"VERB\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key=lambda x: x[1])\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "with open(\"alice.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "text = data[0][2][0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "text = text.replace(\"`\", \"'\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(451313080118390996, 47, 58) 'and what is the use of a book,'\n",
      "(451313080118390996, 60, 67) 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"ORTH\": \"'\"},                   # começa com '\n",
    "           {\"IS_ALPHA\": True, \"OP\": \"+\"},   # precisa ter pelo menos uma letra alfabetica\n",
    "           {\"IS_PUNCT\": True, \"OP\": \"*\"},   # pode ter pontuação\n",
    "           {\"ORTH\": \"'\"}]                   # acaba com '\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key=lambda x: x[1])\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(451313080118390996, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "speak_lemmas = [\"think\", \"say\"]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"ORTH\": \"'\"},                                   # começa com '\n",
    "           {\"IS_ALPHA\": True, \"OP\": \"+\"},                   # precisa ter pelo menos uma letra alfabetica\n",
    "           {\"IS_PUNCT\": True, \"OP\": \"*\"},                   # pode ter pontuação\n",
    "           {\"ORTH\": \"'\"},                                   # acaba com '\n",
    "           {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}},  # vem alguma derivada dos lemas \"think\" ou \"say\" depois\n",
    "           {\"POS\": \"PROPN\", \"OP\": \"+\"},                     # nome próprio que vem depois\n",
    "           {\"ORTH\": \"'\"},                                   # começa com '\n",
    "           {\"IS_ALPHA\": True, \"OP\": \"+\"},                   # precisa ter pelo menos uma letra alfabetica\n",
    "           {\"IS_PUNCT\": True, \"OP\": \"*\"},                   # pode ter pontuação\n",
    "           {\"ORTH\": \"'\"}\n",
    "           ]                  \n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key=lambda x: x[1])\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(451313080118390996, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for text in data[0][2]:\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    matches.sort(key=lambda x: x[1])\n",
    "    print(len(matches))\n",
    "    for match in matches[:10]:\n",
    "        print(match, doc[match[1]:match[2]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "(3232560085755078826, 0, 6) 'Well!' thought Alice\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "(3232560085755078826, 57, 68) 'which certainly was not here before,' said Alice\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "pattern2 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "pattern3 = [{\"POS\": \"PROPN\", \"OP\": \"+\"},{\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern1, pattern2, pattern3], greedy='LONGEST')\n",
    "for text in data[0][2]:\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    matches.sort(key = lambda x: x[1])\n",
    "    print (len(matches))\n",
    "    for match in matches[:10]:\n",
    "        print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
